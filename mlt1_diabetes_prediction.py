# -*- coding: utf-8 -*-
"""mlt_diabetess_prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TRQGWxPAGb2zbyS98Qtie2zNb0LD-rpD

# **Machine Learning Terapan 1 - Diabetes Prediction**

Oleh: M. Zidan Richal Fajril Falah

Proyek ini bertujuan untuk membuat model *predictive analysis* terhadap penyakit diabetes menggunakan dataset [**Pima Indians Diabetes Database**](https://www.kaggle.com/datasets/uciml/pima-indians-diabetes-database) yang tersedia di Kaggle.

## **Import Library**

Pada tahap ini, kita akan mengimpor semua library Python yang dibutuhkan untuk analisis data, visualisasi, dan pemodelan machine learning.
"""

# ===== Built-in libraries =====
import os
import warnings
warnings.filterwarnings('ignore')

# ===== Third-party libraries =====
# -- Data Loading & Manipulation --
import numpy as np
import pandas as pd

# -- Data Visualization --
import matplotlib.pyplot as plt
import seaborn as sns

# -- Data Source --
import kagglehub

# -- Data Cleaning & Preparation --
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# -- Data Splitting & Model Selection --
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score

# -- Modeling Algorithms --
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier, AdaBoostClassifier
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier


# -- Evaluation Metrics --
from sklearn.metrics import (
    accuracy_score,
    classification_report,
    confusion_matrix,
    roc_auc_score,
    roc_curve
)

"""## **1. Data Understanding**

Pada tahap ini, kita akan memahami data yang akan digunakan dalam proyek ini. Proses ini meliputi pengumpulan data, pemahaman struktur data, dan eksplorasi awal untuk mendapatkan insight penting.

### 1.1 Data Loading

Dataset yang digunakan dalam proyek ini adalah dataset Pima Indians Diabetes yang tersedia di Kaggle. Dataset ini akan diunduh menggunakan library kagglehub. Proses ini akan otomatis mengunduh dataset ke direktori yang sesuai.
"""

# Download dataset
path = kagglehub.dataset_download("uciml/pima-indians-diabetes-database")
file_path = os.path.join(path, "diabetes.csv")
print("Path to dataset files:", path)

"""Dataset yang telah diunduh kemudian akan dibaca menggunakan library pandas dan disimpan dalam dataframe `df` Tampilan awal dataframe akan ditampilkan untuk memastikan data telah termuat dengan benar."""

# Load Dataset
df = pd.read_csv(file_path)
df

"""### 1.2 Exploratory Data Analysis - Deskripsi Variabel

Pada tahap ini kita menggunakan `df.info()` melihat, memahami tipe data, distribusi, dan statistik deskriptif dataset.
"""

# Menampilkan info dataset
df.info()

"""ðŸ” **Insight Deskripsi Variabel**

Dataset ini berisi informasi tentang karakteristik kesehatan pasien yang digunakan untuk memprediksi kemungkinan diabetes. Dataset ini terdiri dari **768 sampel (baris) dan 9 fitur (kolom)**. Berikut adalah deskripsi untuk setiap kolom:

- ðŸ¤° **Pregnancies**: Jumlah kehamilan yang pernah dialami oleh pasien. Ini adalah fitur numerik dengan tipe data integer.
- ðŸ¬ **Glucose**: Konsentrasi glukosa plasma dalam darah setelah 2 jam dalam tes toleransi glukosa oral. Ini adalah fitur numerik dengan tipe data integer.
- ðŸ’“ **BloodPressure**: Tekanan darah diastolik (mm Hg). Ini adalah fitur numerik dengan tipe data integer.
- ðŸ“ **SkinThickness**: Ketebalan lipatan kulit trisep (mm). Ini adalah fitur numerik dengan tipe data integer.
- ðŸ’‰ **Insulin**: Kadar insulin serum setelah 2 jam dalam tes toleransi glukosa oral (mu U/ml). Ini adalah fitur numerik dengan tipe data integer.
- âš–ï¸ **BMI**: Indeks Massa Tubuh (Body Mass Index) dihitung dengan berat dalam kg / (tinggi dalam meter)^2. Ini adalah fitur numerik dengan tipe data float.
- ðŸ§¬ **DiabetesPedigreeFunction**: Fungsi riwayat keluarga diabetes, yaitu suatu nilai yang menunjukkan kemungkinan diabetes berdasarkan riwayat keluarga. Ini adalah fitur numerik dengan tipe data float.
- ðŸŽ‚ **Age**: Usia pasien (tahun). Ini adalah fitur numerik dengan tipe data integer.
- âœ… **Outcome**: Variabel target yang menunjukkan apakah pasien didiagnosis diabetes (1) atau tidak (0). Ini adalah fitur kategorikal (biner) dengan tipe data integer.

### 1.3 Exploratory Data Analysis - Univariate Analysis

Pada tahap ini, kita akan melakukan *Univariate Analysis* untuk memahami karakteristik setiap fitur dalam dataset secara individual. *Univariate Analysis* melibatkan eksplorasi distribusi dan pola dari setiap variabel tanpa mempertimbangkan hubungannya dengan variabel lain.

Untuk melakukan univariate analysis, kita akan menghitung *Statistik Deskriptif* dan menggunakan visualisasi *Histogram* untuk setiap fitur numerik dalam dataset.

#### 1.3.1 Statistik Deskriptif

Untuk melakukan statistik deskriptif kita menggunakan `.describe()` untuk melihat ringkasan statistik dataset seperti nilai rata-rata, median, standar deviasi, minimum, dan maksimum, akan memberikan informasi numerik tentang karakteristik data.
"""

# Menampilkan statistik deskriptif
df.describe()

"""ðŸ” **Insight Statistik Deskriptif**

Statistik deskriptif memberikan gambaran umum tentang karakteristik data. Berikut adalah beberapa insight yang didapatkan dari hasil `df.describe()`:

- ðŸ¤° **Pregnancies**: Rata-rata jumlah kehamilan adalah **3.85**, dengan nilai minimum **0** dan maksimum **17**. Terdapat beberapa pasien yang tidak pernah hamil (nilai **0**) dan beberapa pasien dengan jumlah kehamilan yang sangat tinggi. Nilai **0** mungkin mengindikasikan data yang tidak valid atau pasien yang belum pernah hamil.
- ðŸ¬ **Glucose**: Rata-rata kadar glukosa adalah **120.89**, dengan nilai minimum **0** dan maksimum **199**. Terdapat kemungkinan adanya *outlier* atau nilai yang tidak valid, khususnya nilai **0**.
- ðŸ’“ **BloodPressure**: Rata-rata tekanan darah adalah **69.11**, dengan nilai minimum **0** dan maksimum **122**. Nilai **0** mengindikasikan kemungkinan data yang tidak valid.
- ðŸ“ **SkinThickness**: Rata-rata ketebalan lipatan kulit adalah **20.54**, dengan nilai minimum **0** dan maksimum **99**. Kemungkinan terdapat *outlier* atau data tidak valid.
- ðŸ’‰ **Insulin**: Rata-rata kadar insulin adalah **79.80**, dengan nilai minimum **0** dan maksimum **846**. Fitur ini memiliki rentang nilai yang sangat lebar dan kemungkinan terdapat *outlier*.
- âš–ï¸ **BMI**: Rata-rata BMI adalah **31.99**, dengan nilai minimum **0** dan maksimum **67.1**. Nilai **0** mengindikasikan kemungkinan adanya data tidak valid.
- ðŸ§¬ **DiabetesPedigreeFunction**: Rata-rata fungsi riwayat keluarga diabetes adalah **0.47**, dengan nilai minimum **0.08** dan maksimum **2.42**. Ini menunjukkan bahwa sebagian besar pasien memiliki riwayat keluarga diabetes yang relatif rendah.
- ðŸŽ‚ **Age**: Rata-rata usia pasien adalah **33.24 tahun**, dengan usia termuda **21 tahun** dan tertua **81 tahun**. Usia pasien relatif muda, dengan sebagian besar pasien berusia di bawah 50 tahun.
- âœ… **Outcome**: Sekitar **34.9% pasien** (268 dari 768) didiagnosis menderita diabetes (**Outcome = 1**). Ini menunjukkan adanya ketidakseimbangan kelas yang perlu diperhatikan.

ðŸ“Œ **Kesimpulan:**

Beberapa fitur seperti **Glucose**, **BloodPressure**, **SkinThickness**, **Insulin**, dan **BMI** memiliki nilai **0** yang tidak realistis. Hal ini perlu ditangani pada tahap *data cleaning* dengan strategi seperti penghapusan, imputasi, atau transformasi. Selain itu, distribusi target menunjukkan adanya **ketidakseimbangan kelas** yang perlu diperhatikan pada tahap pelatihan model, misalnya dengan menggunakan teknik **oversampling**, **undersampling**, atau **penyesuaian class weight**.

#### 1.3.2 Histogram

Untuk memvisualisasikan distribusi data dan frekuensi kemunculan nilai dalam rentang tertentu, kita menggunakan histogram. Berikut ini adalah histogram dari setiap fitur dalam dataset (kecuali 'Outcome'), yang dibuat menggunakan library `matplotlib.pyplot` dan `seaborn.`
"""

# Histogram Univariate Analysis

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 9))
axes = axes.flatten()

for i, col in enumerate(df.drop('Outcome', axis=1).columns):
    sns.histplot(df[col], ax=axes[i], kde=True, color=sns.color_palette()[i])
    axes[i].set_title(f'Distribution of {col}')

for i in range(len(df.drop('Outcome', axis=1).columns), len(axes)):
    fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

"""ðŸ” **Insight Histogram**

Berikut adalah beberapa insight yang didapatkan:

*   ðŸ¤° **Pregnancies:** Distribusi Pregnancies cenderung menceng ke kanan (right-skewed), dengan sebagian besar pasien memiliki jumlah kehamilan yang rendah. Terdapat beberapa outlier dengan jumlah kehamilan yang tinggi.
*   ðŸ¬ **Glucose:** Distribusi Glucose relatif normal, dengan sebagian besar nilai terpusat di sekitar rata-rata. Namun, terdapat beberapa nilai **0** yang tidak realistis dan perlu diinvestigasi lebih lanjut.
*   ðŸ’“ **BloodPressure:** Distribusi BloodPressure mendekati normal, tetapi terdapat beberapa nilai **0** yang tidak valid.
*   ðŸ“ **SkinThickness:** Distribusi SkinThickness menceng ke kanan, dengan banyak nilai **0** yang perlu ditangani.
*   ðŸ’‰ **Insulin:** Distribusi Insulin sangat menceng ke kanan dan memiliki banyak outlier. Sebagian besar nilai terpusat di sekitar **0**, tetapi terdapat beberapa nilai yang sangat tinggi.
*   âš–ï¸ **BMI:** Distribusi BMI mendekati normal, tetapi terdapat beberapa nilai **0** yang tidak valid.
*   ðŸ§¬ **DiabetesPedigreeFunction:** Distribusi DiabetesPedigreeFunction menceng ke kanan, menunjukkan bahwa sebagian besar pasien memiliki riwayat keluarga diabetes yang rendah.
*   ðŸŽ‚ **Age:** Distribusi Age menceng ke kanan, dengan sebagian besar pasien berusia relatif muda. Terdapat beberapa outlier dengan usia yang lebih tua.

ðŸ“Œ **Kesimpulan:**

Beberapa fitur, seperti **Pregnancies**, **SkinThickness**, **Insulin**, dan **DiabetesPedigreeFunction**, memiliki distribusi yang menceng. Hal ini perlu dipertimbangkan saat melakukan pemodelan. Selain itu, terdapat nilai **0** yang tidak valid pada beberapa fitur, seperti **Glucose**, **BloodPressure**, **SkinThickness**, **Insulin**, dan **BMI**. Nilai-nilai ini perlu ditangani pada tahap data cleaning.
"""

# Visualisasi data untuk label outcome
outcome_counts = df['Outcome'].value_counts()
labels = ['No Diabetes', 'Diabetes']
sizes = outcome_counts.values
colors = sns.color_palette('pastel')

# Membuat pie chart
plt.figure(figsize=(6, 6))
plt.pie(sizes, labels=labels, colors=colors, autopct=lambda p: '{:.1f}%\n({:.0f})'.format(p, p * sum(sizes) / 100), startangle=90,
        textprops={'fontsize': 12})
plt.title('Outcome Distribution', fontsize=14)
plt.show()

"""### 1.4 Exploratory Data Analysis - Multivariate Analysis

Pada tahap ini, kita akan melakukan *Multivariate Analysis* untuk memahami hubungan antar fitur dalam dataset. *Multivariate Analysis* melibatkan eksplorasi hubungan dan pola antara dua atau lebih variabel secara bersamaan.

Untuk melakukan *Multivariate Analysis*, kita akan menggunakan visualisasi *Pair Plot* dan *Correlation Matrix*.

#### 1.4.1 Pair Plot

*Pair plot* akan menampilkan scatter plot untuk setiap pasangan fitur dan histogram untuk setiap fitur individual, memungkinkan kita untuk melihat hubungan dan distribusi data secara visual.
"""

# Pairplot
sns.pairplot(df, hue='Outcome', diag_kind='kde')
plt.show()

"""ðŸ” **Insight Pair Plot**

Pair plot memberikan visualisasi hubungan antar fitur dalam dataset. Berikut adalah beberapa insight yang didapatkan:

*   ðŸ¬âœ… **Hubungan Glucose dan Outcome:** Terlihat bahwa pasien dengan kadar glukosa yang lebih tinggi cenderung memiliki kemungkinan lebih besar untuk didiagnosis diabetes (Outcome = 1). Scatter plot antara Glucose dan Outcome menunjukkan pemisahan yang cukup jelas antara kedua kelompok.
*   ðŸŽ‚âœ… **Hubungan Age dan Outcome:** Usia juga tampaknya berkorelasi dengan diabetes. Pasien yang lebih tua cenderung memiliki risiko diabetes yang lebih tinggi.
*   âš–ï¸âœ… **Hubungan BMI dan Outcome:** BMI yang lebih tinggi juga dikaitkan dengan peningkatan risiko diabetes. Terdapat pola yang menunjukkan bahwa pasien dengan BMI tinggi lebih cenderung didiagnosis diabetes.
*   ðŸ’‰ðŸ¬ **Hubungan Insulin dan Glucose:** Terdapat korelasi positif antara Insulin dan Glucose, yang menunjukkan bahwa pasien dengan kadar glukosa tinggi cenderung memiliki kadar insulin yang tinggi pula. Namun, pola ini tidak terlalu kuat.
*   ðŸ¤°ðŸŽ‚ **Hubungan Pregnancies dan Age:** Terdapat korelasi positif antara jumlah kehamilan (Pregnancies) dan usia (Age), yang merupakan hal yang wajar.
*   ðŸ”— **Korelasi antar Fitur Lain:** Secara umum, korelasi antar fitur lainnya tampak lemah atau tidak signifikan.

ðŸ“Œ **Kesimpulan:**

Dari pair plot, dapat disimpulkan bahwa fitur-fitur seperti **Glucose**, **Age**, dan **BMI** memiliki hubungan yang cukup kuat dengan **Outcome** (diabetes). Fitur-fitur ini berpotensi menjadi prediktor yang baik dalam model machine learning. Hubungan antar fitur lainnya perlu diinvestigasi lebih lanjut untuk menentukan signifikansinya.

#### 1.4.2 Correlation Matrix

*Correlation matrix* akan menunjukkan korelasi antar fitur dalam bentuk tabel, dengan nilai korelasi berkisar antara -1 hingga 1.
"""

# Correlation Matrix
plt.figure(figsize=(10, 8))
correlation_matrix = df.corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f")
plt.title('Correlation Matrix of Diabetes Dataset Features')
plt.show()

"""ðŸ” **Insight Correlation Matrix**

Visualisasi korelasi antar fitur dilakukan untuk memahami hubungan linear antar variabel dalam dataset. Korelasi diukur dengan koefisien Pearson, yang memiliki rentang antara -1 (hubungan negatif sempurna) hingga 1 (hubungan positif sempurna). Berikut insight yang diperoleh:

- ðŸ”— **Korelasi terhadap Variabel Target (Outcome)**

  - ðŸ¬ **Glucose (0.47)** memiliki korelasi tertinggi dengan Outcome, menandakan bahwa kadar glukosa darah sangat berperan dalam prediksi diabetes.
  - âš–ï¸ **BMI (0.29)** menunjukkan korelasi sedang; kelebihan berat badan berkontribusi terhadap risiko diabetes.
  - ðŸŽ‚ **Age (0.24)** memiliki korelasi positif rendah, menunjukkan semakin tua usia, semakin tinggi kemungkinan mengidap diabetes.
  - ðŸ¤° **Pregnancies (0.22)** juga berkorelasi positif terhadap Outcome; jumlah kehamilan dapat menjadi indikator awal risiko diabetes.
  - ðŸ’‰ **Insulin (0.13)**, ðŸ“ **SkinThickness (0.07)**, dan ðŸ’“ **BloodPressure (0.07)** memiliki korelasi sangat rendah terhadap Outcome.

- ðŸ”— **Korelasi Antar Variabel Fitur**

  - ðŸ¤°ðŸŽ‚ **Pregnancies dan Age (0.54)** memiliki korelasi cukup kuat, mengindikasikan bahwa usia berkorelasi positif dengan jumlah kehamilan.
  - ðŸ’‰ðŸ“ **Insulin dan SkinThickness (0.44)** serta ðŸ“âš–ï¸ **SkinThickness dan BMI (0.39)** memiliki korelasi sedang. Hubungan ini logis secara medis karena berkaitan dengan metabolisme dan lemak tubuh.
  - Korelasi antar fitur lainnya tergolong rendah, menandakan minimnya multikolinearitas dalam dataset.

ðŸ“Œ **Kesimpulan**

Fitur **Glucose**, **BMI**, **Age**, dan **Pregnancies** menjadi kandidat utama dalam proses pemodelan karena memiliki korelasi tertinggi dengan target variabel. Sementara fitur lain seperti **Insulin**, **SkinThickness**, dan **BloodPressure** menunjukkan hubungan yang lemah secara linear, namun tetap bisa mengandung informasi penting secara non-linear, khususnya untuk algoritma seperti **Random Forest** atau **Gradient Boosting**.

Jika dimungkinkan, dilakukan feature engineering untuk menangkap interaksi non-linear antar fitur.

Selain itu, normalisasi atau transformasi logaritmik juga bisa dipertimbangkan untuk fitur dengan distribusi miring agar hasil modeling lebih optimal.

### 1.5 Identifikasi Potensi Masalah

berdasarkan hasil EDA yang telah dilakukan sebelumnya, berikut potensi masalah yang teridentifikasi dan perlu diatasi:

#### 1.5.1 Nilai 0 yang Tidak Realistis

Beberapa fitur, seperti Glucose, BloodPressure, SkinThickness, Insulin, dan BMI, memiliki nilai 0 yang tidak realistis secara medis. Ini menunjukkan adanya missing values atau kesalahan input data. Nilai-nilai ini perlu ditangani sebelum pemodelan.

Beberapa Solusi:

- **Imputasi**: Mengganti nilai 0 dengan nilai lain, seperti mean, median, atau nilai yang diprediksi menggunakan metode imputasi seperti KNNImputer.
- **Penghapusan**: Menghapus baris data yang memiliki nilai 0 pada fitur-fitur tersebut, tetapi ini dapat mengurangi jumlah data dan berpotensi menghilangkan informasi penting.

#### 1.5.2 Outliers

Beberapa fitur, seperti Insulin, SkinThickness, dan Pregnancies, memiliki outliers yang dapat mengganggu kinerja model.

Beberapa Solusi:

- **Transformasi**: Menerapkan transformasi logaritmik atau Box-Cox untuk mengurangi pengaruh outliers.
- **Winsorizing**: Membatasi nilai ekstrem pada persentil tertentu untuk mengurangi dampak outliers.
- **Penghapusan**: Menghapus data outliers, tetapi ini perlu dilakukan dengan hati-hati agar tidak menghilangkan informasi penting.

#### 1.5.3 Data Imbalance

Terdapat ketidakseimbangan jumlah data antara kelas 0 (tidak diabetes) dan kelas 1 (diabetes) pada variabel target ('Outcome'). Ini dapat menyebabkan model cenderung memprediksi kelas mayoritas dan kurang akurat dalam memprediksi kelas minoritas.

Beberapa Solusi:

- **Oversampling**: Meningkatkan jumlah data pada kelas minoritas menggunakan teknik seperti SMOTE.
- **Undersampling**: Mengurangi jumlah data pada kelas mayoritas.
- **Penyesuaian Class Weight**: Memberikan bobot yang lebih besar pada kelas minoritas saat melatih model.

#### 1.5.4 Distribusi Data yang Miring

Beberapa fitur, seperti Pregnancies, SkinThickness, Insulin, dan DiabetesPedigreeFunction, memiliki distribusi yang menceng (skewed). Ini dapat memengaruhi kinerja model yang berasumsi data berdistribusi normal.

Beberapa Solusi:

- **Transformasi**: Menerapkan transformasi seperti logaritmik atau Box-Cox untuk menormalkan distribusi data.
- **Capping**: ni adalah teknik penggantian nilai. Nilai-nilai di atas batas atas tertentu (misalnya, persentil ke-99 atau batas atas IQR) diganti dengan nilai batas atas tersebut. Demikian pula, nilai-nilai di bawah batas bawah tertentu (misalnya, persentil ke-1 atau batas bawah IQR) diganti dengan nilai batas bawah tersebut.

#### 1.5.5 Multikolinearitas

Meskipun tidak terlalu tinggi, terdapat beberapa korelasi antar fitur, seperti antara Pregnancies dan Age, serta antara Insulin dan SkinThickness. Multikolinearitas dapat menyebabkan model menjadi tidak stabil dan sulit diinterpretasi.

Beberapa Solusi:

- **Penghapusan Fitur**: Menghapus salah satu fitur yang berkorelasi tinggi.
- **Feature Engineering**: Menggabungkan fitur yang berkorelasi menjadi fitur baru.
- **Menggunakan Algoritma yang Robust**: Menggunakan algoritma machine learning yang lebih robust terhadap multikolinearitas, seperti Random Forest atau Gradient Boosting.

## **2. Data Preparation**

Pada tahap ini, kita akan mempersiapkan data agar siap digunakan untuk pemodelan machine learning. Tahap ini meliputi beberapa langkah penting, yaitu:

### 2.1 Data Cleaning

#### 2.1.1 Pengecekan dan Penanganan Duplikat

Memeriksa dan menghapus data duplikat dalam DataFrame menggunakan `.duplicated()`. Jika ditemukan data duplikat, baris-baris duplikat akan dihapus, dan indeks DataFrame akan direset.
"""

# Periksa data duplikat
num_duplicates = df.duplicated().sum()
print(f"Jumlah data duplikat: {num_duplicates}")

# Hapus data duplikat jika ada
if num_duplicates > 0:
    df.drop_duplicates(inplace=True)
    df.reset_index(drop=True, inplace=True)
    print("Data duplikat telah dihapus.")

"""#### 2.1.2 Pengecekan dan Penanganan Missing Values

Memeriksa jumlah missing values (NaN) di setiap kolom DataFrame menggunakan `.isnull().sum()`.
"""

# Periksa missing values
df.isnull().sum()

"""#### 2.1.3 Pengecekan dan Penanganan Zero Values (Nilai 0 tidak realistis)

Memeriksa jumlah zero values pada fitur-fitur yang telah ditentukan. Jika ditemukan zero values, akan diganti nilai mean pada masing-masing fitur
"""

# Periksa zero values pada fitur-fitur tertentu
zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for feature in zero_features:
    num_zeros = (df[feature] == 0).sum()
    print(f"Jumlah nilai 0 tidak realistis pada {feature}: {num_zeros}")

"""Terdapat sejumlah nilai 0 tidak realistis sesuai daftar berikut:

- Glucose: 5
- BloodPressure: 35
- SkinThickness: 227
- Insulin: 374
- BMI: 11

Seperti yang telah diidentifikasi pada tahap sebelumnya, beberapa fitur memiliki nilai 0 yang tidak realistis. Kita akan mengganti nilai 0 ini dengan mean pada masing-masing fitur
"""

df['Glucose'] = df['Glucose'].where((df['Glucose'] > 0)).fillna(df.groupby('Outcome')["Glucose"].transform("mean"))
df['BMI'] = df['BMI'].where((df['BMI'] > 0)).fillna(df.groupby('Outcome')["BMI"].transform("mean"))
df['BloodPressure'] = df['BloodPressure'].where((df['BloodPressure'] > 0)).fillna(df.groupby('Outcome')["BloodPressure"].transform("mean"))
df['Insulin'] = df['Insulin'].where((df['Insulin'] > 0)).fillna(df.groupby('Outcome')["Insulin"].transform("mean"))
df['SkinThickness'] = df['SkinThickness'].where((df['SkinThickness'] > 0)).fillna(df.groupby('Outcome')["SkinThickness"].transform("mean"))

# Simpan ke df_imputed
df_imputed = df.copy()

"""Kita akan memerikasa ulang nilai 0 tidak realistis, distribusi data dan korelasi antar fitur setelah melewati metode Imputer."""

# Periksa ulang zero values pada fitur-fitur tertentu
zero_features = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']
for feature in zero_features:
    num_zeros = (df_imputed[feature] == 0).sum()
    print(f"Jumlah nilai 0 tidak realistis pada {feature}: {num_zeros}")

"""Dari hasil yang keluar nilai 0 tidak realistis sudah berhasil ditangani, kita akan memeriksa ulang distribusi variabel dan statistik deskriptifnya"""

# Cek ulang distribusi variabel menggunakan Histogram

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 9))
axes = axes.flatten()

for i, col in enumerate(df_imputed.drop('Outcome', axis=1).columns):
    sns.histplot(df_imputed[col], ax=axes[i], kde=True, color=sns.color_palette()[i])
    axes[i].set_title(f'Distribution of {col}')

for i in range(len(df_imputed.drop('Outcome', axis=1).columns), len(axes)):
    fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

# Cek Ulang Statistik Deskriptif

df_imputed.describe()

"""#### 2.1.4 Penanganan Outliers dan Distrbusi Data yang Miring

Pada tahap ini, kita akan mengatasi outlier dan mengelola fitur-fitur dengan distribusi data yang miring. Outlier adalah nilai data yang ekstrem dan dapat memengaruhi kinerja model, sedangkan distribusi yang miring (skewed) dapat melanggar asumsi beberapa algoritma machine learning.

**Identifikasi Outlier:**

Kita akan menggunakan visualisasi Boxplot untuk mendeteksi keberadaan outlier pada setiap fitur numerik. Boxplot menampilkan distribusi data berdasarkan kuartil dan menandai outlier sebagai titik-titik di luar batas whiskers.

**Strategi Penanganan:**

Untuk menangani outlier dan distribusi yang miring, kita akan menggunakan teknik **Capping (Winsorizing)**. Metode ini mengganti nilai-nilai ekstrem (outlier) yang berada di luar batas tertentu (biasanya 1.5 kali jarak interkuartil dari kuartil pertama dan ketiga) dengan nilai ambang batas (batas bawah atau batas atas) yang telah ditentukan. Capping membantu mengurangi dampak outlier tanpa menghapus data, yang penting untuk mempertahankan informasi.

**Langkah-langkah:**

1.  **Visualisasi Boxplot:** Menampilkan boxplot untuk setiap fitur guna mengidentifikasi outlier secara visual.
2.  **Hitung Ambang Batas (Thresholds):** Menggunakan metode IQR (Interquartile Range) untuk menghitung batas bawah dan batas atas untuk mengidentifikasi outlier. Nilai di bawah batas bawah atau di atas batas atas dianggap sebagai outlier.
3.  **Capping Outlier:** Mengganti nilai-nilai outlier dengan batas bawah atau batas atas yang sesuai.
4.  **Pemeriksaan Ulang:** Memvisualisasikan boxplot dan histogram kembali setelah capping untuk memastikan outlier telah ditangani dan distribusi data terlihat lebih baik.
5.  **Pemeriksaan Statistik Deskriptif:** Menampilkan ringkasan statistik deskriptif setelah capping untuk melihat bagaimana nilai-nilai ekstrem telah berubah.

Dengan melakukan capping, kita berharap dapat membuat data lebih stabil dan mengurangi dampak negatif outlier pada proses pemodelan. Meskipun capping mungkin tidak sepenuhnya "menormalkan" distribusi yang sangat miring, ini adalah langkah efektif untuk mengurangi pengaruh nilai-nilai ekstrem.
"""

# Periksa distribusi variabel menggunakan Boxplot

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 9))
axes = axes.flatten()

for i, col in enumerate(df_imputed.drop('Outcome', axis=1).columns):
    sns.boxplot(df_imputed[col], ax=axes[i], color=sns.color_palette()[i])
    axes[i].set_title(f'Distribution of {col}')

for i in range(len(df_imputed.drop('Outcome', axis=1).columns), len(axes)):
    fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

# Fungsi untuk menghitung batas bawah dan atas dengan IQR
def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):
    quartile1 = dataframe[col_name].quantile(q1)
    quartile3 = dataframe[col_name].quantile(q3)
    iqr = quartile3 - quartile1
    low_limit = quartile1 - 1.5 * iqr
    up_limit = quartile3 + 1.5 * iqr
    return low_limit, up_limit

# Fungsi untuk memeriksa apakah kolom memiliki outlier
def check_outlier(dataframe, col_name):
    low_limit, up_limit = outlier_thresholds(dataframe, col_name)
    return dataframe[(dataframe[col_name] < low_limit) | (dataframe[col_name] > up_limit)].any(axis=None)

# Fungsi untuk mengganti nilai outlier dan mencetak jumlah yang diganti
def replace_with_thresholds(dataframe, col_name):
    low_limit, up_limit = outlier_thresholds(dataframe, col_name)
    before = dataframe[col_name].copy()

    # Ganti nilai outlier
    dataframe.loc[dataframe[col_name] < low_limit, col_name] = low_limit
    dataframe.loc[dataframe[col_name] > up_limit, col_name] = up_limit

    # Hitung berapa yang diganti
    after = dataframe[col_name]
    n_capped = sum(before != after)

    if n_capped > 0:
        print(f"Kolom '{col_name}': {n_capped} nilai dicapping ke batas bawah/atas.")
    else:
        print(f"Kolom '{col_name}': tidak ada nilai yang perlu dicapping.")

# Salin df_imputed agar data asli tidak berubah
df_capped = df_imputed.copy()

# Kolom numerik
num_cols = df_capped.select_dtypes(include=['int64', 'float64']).columns

# Proses capping dengan log
for col in num_cols:
    if check_outlier(df_capped, col):
        replace_with_thresholds(df_capped, col)
    else:
        print(f"Kolom '{col}': tidak ditemukan outlier.")

# Periksa ulang distribusi variabel menggunakan Boxplot

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 9))
axes = axes.flatten()

for i, col in enumerate(df_capped.drop('Outcome', axis=1).columns):
    sns.boxplot(df_capped[col], ax=axes[i], color=sns.color_palette()[i])
    axes[i].set_title(f'Distribution of {col}')

for i in range(len(df_capped.drop('Outcome', axis=1).columns), len(axes)):
    fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

# Cek ulang distribusi variabel menggunakan Histogram

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(9, 9))
axes = axes.flatten()

for i, col in enumerate(df_capped.drop('Outcome', axis=1).columns):
    sns.histplot(df_capped[col], ax=axes[i], kde=True, color=sns.color_palette()[i])
    axes[i].set_title(f'Distribution of {col}')

for i in range(len(df_capped.drop('Outcome', axis=1).columns), len(axes)):
    fig.delaxes(axes[i])

plt.tight_layout()
plt.show()

# Cek Ulang Statistik Deskriptif

df_capped.describe()

"""### 2.2 Feature Engineering

Pada tahap ini, kita akan melakukan Feature Engineering, yaitu proses menciptakan fitur-fitur baru dari fitur-fitur yang sudah ada dalam dataset. Tujuan dari feature engineering adalah untuk memberikan informasi tambahan kepada model machine learning yang mungkin tidak terlihat dari fitur-fitur asli. Fitur-fitur baru ini diharapkan dapat meningkatkan kinerja model dalam memprediksi diabetes.

Teknik feature engineering yang akan diterapkan adalah:

**Glucose Insulin Ratio:** Membuat fitur baru dengan menghitung rasio antara kadar Glukosa dan Insulin. Rasio ini dapat memberikan wawasan tentang sensitivitas insulin seseorang, yang merupakan faktor penting dalam diabetes.

Dengan menciptakan fitur baru ini, kita berharap dapat menangkap pola dan hubungan dalam data yang lebih kompleks, yang pada gilirannya dapat meningkatkan akurasi model prediksi diabetes. Setelah proses feature engineering, DataFrame akan memiliki kolom-kolom tambahan yang merepresentasikan fitur-fitur baru ini.
"""

# Glucose Insulin Ratio

df_capped['Glucose_Insulin_Ratio'] = df_capped['Glucose'] / df_capped['Insulin']

df_capped.head()

"""### 2.3 Data Splitting

Pada tahap ini, dataset akan dibagi menjadi dua bagian utama: data latih (training set) dan data uji (testing set).
"""

# Data Spliting

X = df_capped.drop('Outcome', axis=1)
y = df_capped['Outcome']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Menampilkan ukuran masing-masing set
print("Ukuran X_train:", X_train.shape)
print("Ukuran X_test:", X_test.shape)
print("Ukuran y_train:", y_train.shape)
print("Ukuran y_test:", y_test.shape)

"""### 2.4 Normalisasi Data (Data Scaling)

Normalisasi data, atau sering disebut juga Data Scaling, adalah tahap penting dalam *data preprocessing* untuk memastikan bahwa semua fitur numerik memiliki rentang nilai yang serupa. Banyak algoritma machine learning sensitif terhadap skala fitur. Jika fitur-fitur memiliki rentang nilai yang sangat berbeda, fitur dengan rentang yang lebih besar dapat mendominasi proses pembelajaran dan memengaruhi kinerja model secara tidak proporsional.

Dalam tahap ini, kita akan menggunakan **StandardScaler**. StandardScaler bekerja dengan cara menghilangkan mean (rata-rata) dan menskalakan data ke variansi unit. Ini menghasilkan data dengan mean 0 dan standar deviasi 1.
"""

# Inisialisasi StandardScaler
scaler = StandardScaler()

# Tentukan kolom numerik yang akan diskalakan
numerical_cols = ['Pregnancies', 'Glucose', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age', 'Glucose_Insulin_Ratio']

# Fit scaler hanya pada data latih
scaler.fit(X_train[numerical_cols])

# Transform data latih dan data uji
X_train[numerical_cols] = scaler.transform(X_train[numerical_cols])
X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])

"""### 2.5 Data Balancing (pada data training)

SMOTE bekerja dengan cara menghasilkan sampel sintetis baru untuk kelas minoritas. Alih-alih hanya menduplikasi sampel yang sudah ada, SMOTE membuat sampel baru yang merupakan kombinasi dari beberapa sampel terdekat dalam ruang fitur kelas minoritas. Ini membantu memperluas ruang keputusan untuk kelas minoritas tanpa hanya meniru data yang sudah ada.
"""

# Inisialisasi objek SMOTE
smote = SMOTE(random_state=42)  # Anda dapat menyesuaikan random_state jika diperlukan

# Terapkan SMOTE pada data training
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Menampilkan jumlah data sebelum dan sesudah SMOTE
print("Jumlah data sebelum SMOTE:")
print(y_train.value_counts())
print("\nJumlah data sesudah SMOTE:")
print(pd.Series(y_train_smote).value_counts())

"""## **3. Modeling**

Pada tahap ini, kita akan membangun dan melatih model machine learning untuk memprediksi penyakit diabetes berdasarkan data yang telah diproses. Tahap modeling melibatkan beberapa langkah kunci:

### 3.1 Model Selection

Langkah awal adalah memilih algoritma machine learning yang akan digunakan. Untuk proyek ini, kita akan mengevaluasi kinerja beberapa model klasifikasi pohon (tree-based) dan ensemble yang dikenal baik dalam menangani data tabular dan seringkali memberikan hasil yang kuat. Model-model yang dipilih meliputi:

- **Decision Tree Classifier:** Model dasar yang membangun pohon keputusan berdasarkan fitur data.
- **Random Forest Classifier:** Sebuah metode ensemble yang membangun banyak Decision Trees dan menggabungkan prediksi mereka untuk meningkatkan akurasi dan mengurangi *overfitting*.
- **Gradient Boosting Classifier:** Model ensemble lain yang membangun pohon secara sekuensial, di mana setiap pohon baru berusaha memperbaiki kesalahan dari pohon sebelumnya.
- **Extra Trees Classifier:** Mirip dengan Random Forest, tetapi dengan penambahan randomisasi pada proses pemilihan fitur saat membagi node.
- **AdaBoost Classifier:** Metode boosting yang berfokus pada sampel yang sulit diklasifikasikan oleh model sebelumnya.
- **LightGBM Classifier:** Sebuah framework boosting gradient yang cepat dan efisien, seringkali memberikan kinerja tinggi.
- **XGBoost Classifier:** Framework boosting gradient populer lainnya yang dikenal karena kecepatannya dan kinerja yang kuat.
"""

# Inisiasi Model

def base_model():
    """
    Fungsi untuk menginisialisasi model-model dasar.

    Returns:
        dict: Dictionary berisi model-model yang telah diinisialisasi.
    """

    models = {
        'Decision Tree': DecisionTreeClassifier(),
        'Random Forest': RandomForestClassifier(),
        'Gradient Boosting': GradientBoostingClassifier(),
        'Extra Trees': ExtraTreesClassifier(),
        'AdaBoost': AdaBoostClassifier(),
        'LightGBM': LGBMClassifier(verbose=-1),
        'XGBoost': XGBClassifier()
    }
    return models

models = base_model()

"""### 3.2 Model Training

Setelah model-model dasar dipilih, tahap selanjutnya adalah melatih setiap model menggunakan data latih yang sudah diseimbangkan dengan SMOTE (`X_train_smote`, `y_train_smote`). Proses pelatihan melibatkan model mempelajari pola dari data untuk dapat membuat prediksi.

Setelah setiap model dilatih, kita akan segera melakukan evaluasi awal dengan memprediksi *outcome* pada data uji yang belum pernah dilihat (`X_test`) dan menghitung metrik akurasi (`accuracy_score`). Akurasi awal ini akan memberikan gambaran kasar tentang kinerja setiap model sebelum *hyperparameter tuning*.
"""

# 3.2 Model Training
for name, model in models.items():
    print(f"Training {name}...")
    model.fit(X_train_smote, y_train_smote)
    print(f"{name} trained.")

    # Prediksi pada data pengujian
    y_pred = model.predict(X_test)

    # Hitung dan tampilkan akurasi
    accuracy = accuracy_score(y_test, y_pred)
    print(f"Accuracy for {name}: {accuracy:.4f}", end="\n\n")

"""### 3.3 Hyperparameter Tuning

Kinerja model machine learning sangat bergantung pada *hyperparameter* yang digunakan. *Hyperparameter* adalah parameter konfigurasi eksternal yang tidak dipelajari dari data, tetapi diatur sebelum proses pelatihan dimulai. Contoh *hyperparameter* termasuk jumlah pohon dalam Random Forest (`n_estimators`), kedalaman maksimum pohon (`max_depth`), dan *learning rate* dalam model boosting.

Tahap *hyperparameter tuning* bertujuan untuk menemukan kombinasi *hyperparameter* terbaik untuk setiap model agar memaksimalkan kinerjanya pada data. Kita akan menggunakan teknik **Grid Search with Cross-Validation** untuk melakukan tuning.

**Grid Search** akan mengeksplorasi semua kombinasi *hyperparameter* yang ditentukan dalam *parameter grid* untuk setiap model. **Cross-Validation (CV)**, dalam hal ini dengan 5 lipatan (cv=5), akan membagi data latih menjadi 5 bagian. Model akan dilatih pada 4 bagian dan divalidasi pada 1 bagian yang tersisa secara bergiliran. Ini dilakukan 5 kali, dan kinerja dirata-ratakan. Metode ini memberikan estimasi kinerja model yang lebih robust dan tidak terlalu sensitif terhadap pembagian data tertentu.

**Langkah-langkah:**

1.  **Definisikan Parameter Grid:** Menentukan *dictionary* (`param_grids`) yang berisi daftar *hyperparameter* dan rentang nilai yang ingin diuji untuk setiap model.
2.  **Inisialisasi GridSearchCV:** Membuat objek `GridSearchCV` untuk setiap model, menentukan estimator (model), *parameter grid*, jumlah lipatan CV (cv=5), dan pengaturan lain seperti `n_jobs` (untuk menggunakan semua core CPU) dan `verbose` (untuk mengontrol output).
3.  **Lakukan Grid Search:** Melatih objek `GridSearchCV` pada data latih yang diseimbangkan (`X_train_smote`, `y_train_smote`). GridSearchCV akan melakukan proses pelatihan dan validasi silang untuk setiap kombinasi *hyperparameter* dalam grid.
4.  **Dapatkan Model Terbaik:** Setelah Grid Search selesai, kita akan mendapatkan model terbaik (`best_estimator_`) untuk setiap algoritma yang telah dilatih dengan kombinasi *hyperparameter* terbaik yang ditemukan. Model terbaik ini akan disimpan.
5.  **Evaluasi Model Terbaik:** Model terbaik dari setiap algoritma akan dievaluasi kembali pada data uji (`X_test`) untuk mendapatkan metrik kinerja akhir (dalam kode ini, akurasi). Hasil tuning dan kinerja model terbaik akan dicatat.

Dengan melakukan *hyperparameter tuning*, kita berharap dapat meningkatkan kinerja model-model yang dipilih dan mengidentifikasi model mana yang paling menjanjikan untuk prediksi diabetes pada dataset ini.
"""

# Parameter Grid

rf_params = {
    "max_depth": [10, 15, None],
    "max_features": ["sqrt", "log2", 5],
    "min_samples_split": [5, 10],
    "n_estimators": [100, 200]
}

decision_tree_params = {
    'max_depth': [None, 5, 10, 15],
    'min_samples_split': [2, 5, 10, 15],
    'min_samples_leaf': [1, 2, 4, 8]
}

gradient_boosting_params = {
    'n_estimators': [100, 200, 300],
    'learning_rate': [0.01, 0.1, 0.2],
    'max_depth': [3, 5, 7],
    'subsample': [0.8, 1.0]
}

extra_trees_params = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 5, 10],
    'min_samples_split': [2, 5, 10]
}

adaboost_params = {
    'n_estimators': [50, 100, 200],
    'learning_rate': [0.01, 0.1, 1.0]
}

lightgbm_params = {
    "learning_rate": [0.01, 0.1],
    "n_estimators": [300, 500],
    "colsample_bytree": [0.7, 1],
    "num_leaves": [15, 31],
    "max_depth": [-1, 5, 10],
    "subsample": [0.8, 1.0]
}

xgboost_params = {
    "learning_rate": [0.1, 0.01],
    "max_depth": [5, 8],
    "n_estimators": [100, 200],
    "colsample_bytree": [0.5, 1],
    "subsample": [0.8, 1.0]
}


param_grids = {
    'Decision Tree': decision_tree_params,
    'Random Forest': rf_params,
    'Gradient Boosting': gradient_boosting_params,
    'Extra Trees': extra_trees_params,
    'AdaBoost': adaboost_params,
    'LightGBM': lightgbm_params,
    'XGBoost': xgboost_params
}

# Tuning Model

best_models = {}
tuning_results = []

for name, model in models.items():
    print(f"ðŸ”§ Tuning {name}...")
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=param_grids[name],
        cv=5,
        n_jobs=-1,
        verbose=0
    )
    grid_search.fit(X_train_smote, y_train_smote)

    best_model = grid_search.best_estimator_
    best_models[name] = best_model

    # Prediksi pada data test
    y_pred = best_model.predict(X_test)
    test_acc = accuracy_score(y_test, y_pred)

    # Simpan hasil tuning
    tuning_results.append({
        'Model': name,
        'Best Parameters': grid_search.best_params_,
        'Best CV Score': round(grid_search.best_score_, 4),
        'Test Accuracy': round(test_acc, 4)
    })

    print(f"âœ… {name} tuned.")
    print(f"   Best Params: {grid_search.best_params_}")
    print(f"   CV Score: {grid_search.best_score_:.4f}")
    print(f"   Test Accuracy: {test_acc:.4f}\n")

# Tampilkan hasil tuning dalam bentuk tabel
tuning_df = pd.DataFrame(tuning_results)
tuning_df = tuning_df.set_index('Model')
print("\nðŸ“‹ Tuning Summary:")
display(tuning_df)

"""### 3.4 Memilih Best Model untuk Dievaluasi"""

# Urutkan berdasarkan Test Accuracy untuk menentukan model terbaik
best_model_summary = tuning_df.sort_values(by='Test Accuracy', ascending=False)

print("\nðŸ… Best Model based on Test Accuracy:")
display(best_model_summary)

# Pilih model terbaik
best_model_name = best_model_summary.index[0]
final_model = best_models[best_model_name]

print(f"\nðŸŽ‰ The best model selected is: {best_model_name}")

"""## **4. Model Evaluation**

### 4.1 Membuat Prediksi dengan Model Terbaik
"""

# Melakukan prediksi pada data uji
y_pred = final_model.predict(X_test)

# Untuk ROC AUC, butuh probabilitas kelas positif
if hasattr(final_model, "predict_proba"):
    y_pred_proba = final_model.predict_proba(X_test)[:, 1]
else:
    # Fallback jika predict_proba tidak tersedia
    y_pred_proba = y_pred
    print(f"Peringatan: {best_model_name}.predict_proba() tidak tersedia. ROC AUC mungkin tidak akurat.")

print(f"Prediksi dengan {best_model_name} telah dibuat.")

"""### 4.2 Akurasi dan Confusion Matrix untuk final_model (Random Forest)"""

# Menghitung Akurasi (sebagai konfirmasi)
accuracy = accuracy_score(y_test, y_pred)
print(f"ðŸŽ¯ Akurasi {best_model_name} pada Data Uji: {accuracy:.4f}")
print("-" * 70)

# Menghitung dan Menampilkan Confusion Matrix
print(f"ðŸ“Š Confusion Matrix untuk {best_model_name}:")
cm = confusion_matrix(y_test, y_pred)
print(cm)
print("-" * 70)

# Visualisasi Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False,
            xticklabels=['Tidak Diabetes', 'Diabetes'],
            yticklabels=['Tidak Diabetes', 'Diabetes'])
plt.xlabel('Prediksi Label')
plt.ylabel('Label Sebenarnya')
plt.title(f'Confusion Matrix - {best_model_name}')
plt.show()

"""### 4.3 Laporan Klasifikasi (Classification Report) untuk final_model (Random Forest)"""

# Menampilkan Laporan Klasifikasi
print(f"ðŸ“„ Laporan Klasifikasi untuk {best_model_name}:")
report = classification_report(y_test, y_pred, target_names=['Tidak Diabetes (0)', 'Diabetes (1)'])
print(report)

"""### 4.4 ROC AUC Score dan Kurva ROC untuk final_model (Random Forest)"""

# Menghitung dan Menampilkan ROC AUC Score
if hasattr(final_model, "predict_proba"):
    roc_auc = roc_auc_score(y_test, y_pred_proba)
    print(f"ðŸ“ˆ ROC AUC Score untuk {best_model_name}: {roc_auc:.4f}")
    print("-" * 70)

    # Visualisasi Kurva ROC
    fpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, color='blue', lw=2, label=f'{best_model_name} (AUC = {roc_auc:.2f})')
    plt.plot([0, 1], [0, 1], color='grey', lw=2, linestyle='--') # Garis referensi (random guess)
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate (1 - Specificity)')
    plt.ylabel('True Positive Rate (Sensitivity/Recall)')
    plt.title(f'Receiver Operating Characteristic (ROC) Curve - {best_model_name}')
    plt.legend(loc="lower right")
    plt.grid(True)
    plt.show()
else:
    print(f"Kurva ROC tidak dapat ditampilkan untuk {best_model_name} karena predict_proba tidak tersedia.")

"""### 4.5 Feature Importance"""

if hasattr(final_model, 'feature_importances_'):
    # Dapatkan feature importances dari model terbaik
    feature_importances = final_model.feature_importances_

    # Buat DataFrame untuk visualisasi
    features_df = pd.DataFrame({
        'Feature': X.columns,
        'Importance': feature_importances
    })

    # Urutkan berdasarkan Importance
    features_df = features_df.sort_values(by='Importance', ascending=False)

    # Tampilkan feature importances
    print("ðŸ“Š Feature Importances:\n")
    display(features_df)

    # Visualisasikan feature importances
    plt.figure(figsize=(10, 6))
    sns.barplot(x='Importance', y='Feature', data=features_df, palette='viridis')
    plt.title(f'Feature Importance - {best_model_name}')
    plt.xlabel('Importance')
    plt.ylabel('Feature')
    plt.tight_layout()
    plt.show()
elif hasattr(final_model, 'coef_'):
    print(f"Model {best_model_name} memiliki atribut 'coef_' bukan 'feature_importances_'.")
    print("Feature importances untuk model linear:")
    coef_df = pd.DataFrame({
        'Feature': X.columns,
        'Coefficient': final_model.coef_[0] if final_model.coef_.ndim > 1 else final_model.coef_
    })
    coef_df = coef_df.sort_values(by='Coefficient', ascending=False)
    display(coef_df)
else:
    print(f"Model {best_model_name} tidak memiliki atribut feature_importances_ atau coef_.")
    print("Tidak dapat menampilkan feature importance.")

"""Tabel berikut menunjukkan kontribusi masing-masing fitur terhadap keputusan model Random Forest. Angka yang lebih tinggi menunjukkan pengaruh yang lebih besar terhadap prediksi diabetes.

| Rank  | Feature                  | Importance   |
| ----- | ------------------------ | ------------ |
| **1** | **Insulin**              | **0.448762** |
| **2** | SkinThickness            | 0.112620     |
| **3** | Age                      | 0.108688     |
| **4** | Glucose                  | 0.102226     |
| **5** | Glucose_Insulin_Ratio    | 0.091267     |
| **6** | BMI                      | 0.045567     |
| **7** | DiabetesPedigreeFunction | 0.040259     |
| **8** | BloodPressure            | 0.026875     |
| **9** | Pregnancies              | 0.023736     |



**Interpretasi Feature Importance**

1. **Insulin (0.4487)** â†’ menjadi faktor paling dominan.
   Level insulin berhubungan erat dengan resistensi insulin, kondisi fisiologis utama penyebab diabetes tipe 2.

2. **SkinThickness & BMI** â†’ indikator lemak tubuh â†’ berkaitan dengan risiko metabolik.

3. **Age** â†’ semakin tua usia, semakin tinggi risiko diabetes.

4. **Glucose** â†’ tetap menjadi fitur penting dalam diagnosis, sesuai standar medis.

5. **Glucose_Insulin_Ratio** â†’ fitur rekayasa (feature engineering) yang kamu buat memberikan kontribusi signifikan, membuktikan keberhasilan proses pembuatan fitur.

6. **DiabetesPedigreeFunction** â†’ faktor genetika tetap berpengaruh, namun tidak sebesar faktor fisiologis (insulin, glucose, BMI).

7. **Pregnancies** â†’ berpengaruh kecil tetapi relevan (terutama gestational diabetes).

### 4.6 Import Joblib
"""

import joblib

# Simpan final model
joblib.dump(final_model, 'final_diabetes_model.joblib')

# Simpan scaler
joblib.dump(scaler, 'scaler.joblib')

print("Final model dan scaler berhasil disimpan.")

"""## **5. Kesimpulan**

Proyek ini bertujuan membangun model *predictive analysis* untuk memprediksi risiko diabetes menggunakan dataset Pima Indians Diabetes Database. Melalui tahapan Data Understanding, Data Preparation, Modeling, dan Model Evaluation, beberapa poin utama dapat disimpulkan:

1. **Pemahaman Data Awal**
    
    Dataset menunjukkan adanya beberapa masalah seperti nilai 0 yang tidak realistis pada fitur Glucose, Blood Pressure, Skin Thickness, Insulin, dan BMI, keberadaan *outlier*, serta ketidakseimbangan kelas pada variabel target. Fitur-fitur seperti **Glucose**, **BMI**, dan **Age** teridentifikasi memiliki pengaruh signifikan terhadap outcome diabetes berdasarkan analisis awal korelasi.

2. **Persiapan Data yang Efektif**

    Berbagai permasalahan data berhasil ditangani melalui proses *data cleaning* dan *feature engineering*, meliputi:
    * Imputasi nilai 0 dengan mean berdasarkan kelompok outcome,
    * Capping *outlier* menggunakan Winsorizing,
    * Pembuatan fitur baru seperti **Glucose-Insulin Ratio**,
    * Penanganan ketidakseimbangan kelas menggunakan **SMOTE**,
    * Normalisasi fitur numerik menggunakan **StandardScaler**.
      Tahapan ini berkontribusi pada peningkatan kualitas data sebelum dilakukan pemodelan.

3. **Evaluasi Model yang Komprehensif**

    Berbagai model tree-based dan ensemble diuji, seperti Decision Tree, Random Forest, Gradient Boosting, Extra Trees, AdaBoost, LightGBM, dan XGBoost.
    Proses **hyperparameter tuning** dilakukan menggunakan Grid Search dan Cross-Validation (cv=5) untuk memperoleh konfigurasi model terbaik.

4. **Kinerja Model Terbaik**

    Model terbaik dipilih berdasarkan performa pada data uji dan dievaluasi menggunakan metrik:

    * **Confusion Matrix**,
    * **Precision, Recall, dan F1-Score**,
    * **Accuracy**,
    * **ROC AUC Score**.

    Hasil evaluasi menunjukkan bahwa model memiliki kemampuan yang baik dalam membedakan antara pasien diabetes dan non-diabetes, serta mendeteksi kasus diabetes secara efektif.

5. **Feature Importance (Fitur yang Paling Berpengaruh)**

    Analisis feature importance pada model terbaik menunjukkan bahwa beberapa fitur memiliki kontribusi besar dalam proses prediksi:

    * **Insulin** merupakan fitur paling berpengaruh dengan importance tertinggi (0.4487), menunjukkan perannya yang kuat dalam membedakan risiko diabetes.
    * **SkinThickness**, **Age**, dan **Glucose** juga memberikan kontribusi penting terhadap keputusan model.
    * Fitur hasil rekayasa, seperti **Glucose-Insulin Ratio**, memberikan pengaruh yang signifikan, mendukung keberhasilan proses feature engineering.
    * Fitur lain seperti BMI, DiabetesPedigreeFunction, BloodPressure, dan Pregnancies memiliki pengaruh lebih rendah namun tetap relevan dalam interpretasi risiko.

    Analisis ini membantu memahami bagaimana model membuat keputusan dan fitur mana yang paling berperan dalam prediksi diabetes.

**Kesimpulan Akhir**

Secara keseluruhan, proyek ini berhasil mengembangkan model prediksi diabetes yang robust dengan menangani masalah data secara komprehensif dan mengevaluasi kinerja model dengan metrik yang tepat.
Model yang dipilih menunjukkan performa yang menjanjikan untuk digunakan sebagai alat skrining awal, meskipun diperlukan validasi lanjutan dengan dataset yang lebih luas dan bervariasi untuk memastikan generalisasi dan akurasi model di lingkungan nyata.

## **6. Rekomendasi**

Beberapa rekomendasi untuk implementasi model di lingkungan nyata:

1. **Gunakan model sebagai alat skrining awal**, bukan diagnosis akhir.
2. **Integrasikan ke sistem klinis** agar dapat memberikan peringatan risiko diabetes secara otomatis.
3. **Lakukan pelatihan model menggunakan data rumah sakit lokal**, karena variasi demografis dapat memengaruhi performa.
4. **Monitor performa model secara berkala**, terutama nilai Recall pada kelas diabetes.
5. **Kolaborasi dengan tenaga medis** untuk menerjemahkan output model ke dalam keputusan klinis yang aman.

## **7. Limitasi Model**

Beberapa batasan yang perlu diperhatikan:

* Dataset relatif **kecil (768 sampel)** â†’ risiko overfitting.
* Tidak mencakup data klinis yang lebih kompleks seperti riwayat keluarga, pola makan, atau gaya hidup.
* Fitur Insulin memiliki banyak missing yang tidak langsung terlihat (bernilai 0).
* Performanya dapat menurun ketika digunakan pada populasi berbeda (misalnya ras atau usia yang berbeda).
* SMOTE menambah data sintetis yang mungkin tidak sepenuhnya mencerminkan kondisi nyata.

## **8. Saran untuk Pengembangan Selanjutnya**

Model dapat ditingkatkan dengan:

1. **Mengumpulkan dataset yang lebih besar dan lebih bervariasi.**
2. **Menggunakan teknik balancing lain** seperti ADASYN atau SMOTEENN untuk membandingkan hasil.
3. **Mengeksplorasi model lain seperti CatBoost**, yang sering unggul pada data tabular.
4. **Menerapkan teknik explainable AI** seperti SHAP untuk interpretasi lebih dalam.
5. **Membangun pipeline deployment** (API/Streamlit dashboard) agar model bisa digunakan end-user.
6. **Melakukan hyperparameter tuning yang lebih luas** menggunakan RandomizedSearch atau Bayesian Optimization.
"""